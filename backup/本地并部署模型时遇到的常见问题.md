# 本地并部署模型时遇到的常见问题

[建议搭配博客查看
本地部署模型（ollama为例）](https://wmsheep.github.io/WM-sheep.github.io/post/ben-di-bu-shu-mo-xing-%EF%BC%88ollama-wei-li-%EF%BC%89.html)
---
## 运行问题：
> - 当部署完成以后，想要**再次运行**时，只需要：
>   1. **打开 `PowerShell` （无需管理员身份）**
>   2. 输入**对应模型的安装命令**即可

## 模型不可用问题：
> - 输入下载命令发现***模型不可用问题***——
>   1. 检查 **Ollama Setup.exe** 是否正常【**打开`PowerShell`（无需管理员身份**】[输入**ollama**查看输出。正常输出如下]
****
``` txt
PS C:\Users\用户名> ollama
Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use "ollama [command] --help" for more information about a command.
PS C:\Users\用户名>
```

**[下载模型正常输出]**
```
PS C:\Users\wmy66> ollama run llama3.1:8b
pulling manifest
pulling 8eeb52dfb3bb...
91%▕██████████████████████████████████████████████████      ▏ 
4.2 GB/4.7 GB  207 KB/s  35m26s 
```
****
若是这段输出**Ollama Setup.exe**基本正常，若还是不行就**重新下载** **[点我查看博客](https://wmsheep.github.io/WM-sheep.github.io/post/ben-di-bu-shu-mo-xing-%EF%BC%88ollama-wei-li-%EF%BC%89.html)**
要么就是**模型与电脑配置不匹配**，**换一个模型**

## 语言问题：
> - 这个模型默认语言是英语，对于大陆用户来说，要让让它用中文回复只需一步
>   1. 输入`请用中文回复`即可

---

## 模型卡顿问题：
> - 模型卡顿问题，一般是因为**显卡显存不足**，解决方法如下：
>   1. **关闭**电脑上其他**占用显存**的软件


[建议搭配博客查看
本地部署模型（ollama为例）](https://wmsheep.github.io/WM-sheep.github.io/post/ben-di-bu-shu-mo-xing-%EF%BC%88ollama-wei-li-%EF%BC%89.html)
---